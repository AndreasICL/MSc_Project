{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VFF_and_RFF_1D.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOQP/BaV8YRxzPuO6NJEG6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreasICL/MSc_Project/blob/master/code/VFF_and_RFF_1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW-B5syh75r4",
        "colab_type": "code",
        "outputId": "b5278b6d-2406-48d9-fd9b-9df24c49608b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!pip install gpflow\n",
        "!pip install gast\n",
        "!pip install observations"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpflow in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from gpflow) (1.4.1)\n",
            "Requirement already satisfied: multipledispatch>=0.6 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.6.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from gpflow) (2.2.0rc4)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from gpflow) (1.18.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from gpflow) (3.6.6)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.8.7)\n",
            "Requirement already satisfied: gast<0.3,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-probability>=0.9 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.10.0rc0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from multipledispatch>=0.6->gpflow) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.2.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (3.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.28.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9->gpflow) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9->gpflow) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow->gpflow) (46.1.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.6.0.post3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2020.4.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.4.8)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: observations in /usr/local/lib/python3.6/dist-packages (0.1.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from observations) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from observations) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3cwbeHz8Exr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Tuple, Optional\n",
        "import tempfile\n",
        "import pathlib\n",
        "\n",
        "import datetime\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gpflow\n",
        "\n",
        "from gpflow.config import default_float\n",
        "from gpflow.ci_utils import ci_niter\n",
        "from gpflow.utilities import to_default_float\n",
        "from gpflow.base import TensorLike\n",
        "from gpflow import covariances as cov\n",
        "from gpflow import kullback_leiblers as kl\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "from shutil import copyfile, rmtree\n",
        "\n",
        "import observations\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5FxoiegAZe1",
        "colab_type": "text"
      },
      "source": [
        "Make `tensorboard` work inside notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmCOr2hs8355",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_logdir = \"/tmp/tensorboard\"\n",
        "\n",
        "!rm -rf \"{output_logdir}\"\n",
        "!mkdir \"{output_logdir}\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def enumerated_logdir(_logdir_id: int = [0]):\n",
        "    logdir = pathlib.Path(output_logdir, str(_logdir_id[0]))\n",
        "    _logdir_id[0] += 1\n",
        "    return str(logdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A27JdlvAZfE",
        "colab_type": "text"
      },
      "source": [
        "Set up random seeds and default float for `gpflow` tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flnWsQF1_h3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpflow.config.set_default_float(np.float64)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJsA3bUEAZfP",
        "colab_type": "text"
      },
      "source": [
        "## Loading the snelson dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZDkEmxQEqqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  This code was copied from https://github.com/edwardlib/observations/blob/master/observations/snelson1d.py\n",
        "  on 01/05/2020\n",
        "'''\n",
        "\n",
        "from observations.util import maybe_download_and_extract\n",
        "\n",
        "\n",
        "def snelson1d(path):\n",
        "  \"\"\"Load Edward Snelson's 1d regression data set [@snelson2006fitc].\n",
        "  It contains 200 examples of a few oscillations of an example function. It has\n",
        "  seen extensive use as a toy dataset for illustrating qualitative behaviour of\n",
        "  Gaussian process approximations.\n",
        "  Args:\n",
        "    path: str.\n",
        "      Path to directory which either stores file or otherwise file will be\n",
        "      downloaded and extracted there. Filenames are `snelson_train_*`.\n",
        "  Returns:\n",
        "    Tuple of two np.darray `inputs` and `outputs` with 200 rows and 1 column.\n",
        "  \"\"\"\n",
        "  path = os.path.expanduser(path)\n",
        "  inputs_path = os.path.join(path, 'snelson_train_inputs')\n",
        "  outputs_path = os.path.join(path, 'snelson_train_outputs')\n",
        "\n",
        "  # Contains all source as well. We just need the data.\n",
        "  url = 'http://www.gatsby.ucl.ac.uk/~snelson/SPGP_dist.zip'\n",
        "\n",
        "  if not (os.path.exists(inputs_path) and os.path.exists(outputs_path)):\n",
        "    maybe_download_and_extract(path, url)\n",
        "\n",
        "    # Copy the required data\n",
        "    copyfile(os.path.join(path, \"SPGP_dist\", \"train_inputs\"), inputs_path)\n",
        "    copyfile(os.path.join(path, \"SPGP_dist\", \"train_outputs\"), outputs_path)\n",
        "\n",
        "    # Clean up everything else\n",
        "    rmtree(os.path.join(path, \"SPGP_dist\"))\n",
        "    os.remove(os.path.join(path, \"SPGP_dist.zip\"))\n",
        "\n",
        "  X = np.loadtxt(os.path.join(inputs_path))[:, None]\n",
        "  Y = np.loadtxt(os.path.join(outputs_path))[:, None]\n",
        "\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cwgLNj8Hw2h",
        "colab_type": "code",
        "outputId": "2a518f60-9b94-418b-ecee-ff0ff8f8c871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "X, Y = snelson1d(\".\")\n",
        "num_train_data = X.shape[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Downloading ./SPGP_dist.zip.part \n",
            ">> [14.7 KB/14.7 KB] 6944% @3.3 MB/s,[0s remaining, 0s elapsed]        \n",
            "URL http://www.gatsby.ucl.ac.uk/~snelson/SPGP_dist.zip downloaded to ./SPGP_dist.zip \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg8Cz-6OAZfb",
        "colab_type": "text"
      },
      "source": [
        "Working with TensorFlow Datasets is an efficient way to rapidly shuffle, iterate, and batch from data. For `prefetch` size we use `tf.data.experimental.AUTOTUNE` as recommended by TensorFlow [guidelines](https://www.tensorflow.org/guide/data_performance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUfgEr7aAZfc",
        "colab_type": "code",
        "outputId": "ab76002c-895b-4faa-e535-0ffb651b535e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((Xtest, Ytest))\n",
        "\n",
        "batch_size = 32\n",
        "num_features = 10\n",
        "prefetch_size = tf.data.experimental.AUTOTUNE\n",
        "shuffle_buffer_size = num_train_data // 2\n",
        "num_batches_per_epoch = num_train_data // batch_size\n",
        "\n",
        "original_train_dataset = train_dataset\n",
        "train_dataset = (\n",
        "    train_dataset.repeat()\n",
        "    .prefetch(prefetch_size)\n",
        "    .shuffle(buffer_size=shuffle_buffer_size)\n",
        "    .batch(batch_size)\n",
        ")\n",
        "\n",
        "print(f\"prefetch_size={prefetch_size}\")\n",
        "print(f\"shuffle_buffer_size={shuffle_buffer_size}\")\n",
        "print(f\"num_batches_per_epoch={num_batches_per_epoch}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prefetch_size=-1\n",
            "shuffle_buffer_size=100\n",
            "num_batches_per_epoch=6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJdIiObeAZfm",
        "colab_type": "text"
      },
      "source": [
        "## Define a GP model\n",
        "\n",
        "In GPflow 2.0, we use `tf.Module` (or the very thin `gpflow.base.Module` wrapper) to build all our models, as well as their components (kernels, likelihoods, parameters, and so on)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCqAtzWBUhax",
        "colab_type": "text"
      },
      "source": [
        "### 1D Random Variational Fourier Feature Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqaFm4vuUgwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RVFF_1D(gpflow.inducing_variables.InducingVariables):\n",
        "    def __init__(self, a, b, M):\n",
        "        # [a, b] defining the interval of the Fourier representation:\n",
        "        self.a = gpflow.Parameter(a, dtype=gpflow.default_float())\n",
        "        self.b = gpflow.Parameter(b, dtype=gpflow.default_float())\n",
        "        # integer array defining the frequencies, ω_m = 2π (b - a)/m:\n",
        "        self.omegas = 2.0 * np.pi * np.arange(M, dtype=default_float()) / (b - a) + 1 # TODO: fix this\n",
        "        self.phis = np.random.multivariate_normal( mean=a * np.ones( shape=M ), cov=np.identity( M ) )\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" number of inducing variables (defines dimensionality of q(u)) \"\"\" \n",
        "        return len(self.omegas)  # M sine components"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi5s0D0rlFoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@cov.Kuu.register(RVFF_1D, gpflow.kernels.Matern12)\n",
        "def Kuu_matern12_RVFF_1D(inducing_variable, kernel, jitter=None):\n",
        "    a, b, omegas, phis = (lambda u: (u.a, u.b, u.omegas, u.phis))(inducing_variable)\n",
        "    \n",
        "    lambda_ = 1.0 / kernel.lengthscales\n",
        "\n",
        "    def innerProduct( intervalLen, omegas, phis, kernelVar, lambda_):\n",
        "      angle1 = intervalLen * ( omegas[:, None] - omegas[None, :] ) + omegas[:, None] * phis[:, None] - omegas[None, :] * phis[None, :]\n",
        "      angle2 = intervalLen * ( omegas[:, None] + omegas[None, :] ) + omegas[:, None] * phis[:, None] + omegas[None, :] * phis[None, :]\n",
        "      angle3 = omegas[:, None] * phis[:, None] - omegas[None, :] * phis[None, :]\n",
        "      angle4 = omegas[:, None] * phis[:, None] + omegas[None, :] * phis[None, :]\n",
        "      angle5 = 2 * omegas * ( intervalLen + phis )\n",
        "      angle6 = 2 * omegas * phis\n",
        "\n",
        "      coeff1 = ( omegas[:, None] * omegas[None, :] + lambda_ * lambda_ ) / ( omegas[:, None] - omegas[None, :] )\n",
        "      coeff2 = ( omegas[:, None] * omegas[None, :] - lambda_ * lambda_ ) / ( omegas[:, None] + omegas[None, :] )\n",
        "      coeff3 = ( omegas * omegas - lambda_ * lambda_ ) / ( 2 * omegas )\n",
        "\n",
        "      denom = 4 * kernelVar * kernelVar * lambda_\n",
        "\n",
        "      firstTerm = ( coeff1 * tf.sin( angle1 ) +\n",
        "                    coeff2 * tf.sin( angle2 ) -\n",
        "                    lambda_ * tf.cos( angle2 ) +\n",
        "                    lambda_ * tf.cos( angle1 ) +\n",
        "                    coeff1 * tf.sin( angle3 ) +\n",
        "                    coeff2 * tf.sin( angle4 ) -\n",
        "                    lambda_ * tf.cos( angle4 ) +\n",
        "                    lambda_ * tf.cos( angle3 ) ) / denom\n",
        "\n",
        "      mainDiag = ( ( omegas * omegas + lambda_ * lambda_ ) * intervalLen + \n",
        "                   coeff3 * tf.sin( angle5 ) -\n",
        "                   ( lambda_ * tf.cos( angle5 ) ) - \n",
        "                   ( coeff3 * tf.sin( angle6 ) ) +\n",
        "                   lambda_ * tf.cos( angle6 ) ) / denom\n",
        "\n",
        "      firstTerm = tf.linalg.set_diag( firstTerm, mainDiag )\n",
        "      secondTerm = tf.sin( omegas[:, None] * phis[:, None] ) * tf.sin( omegas[None, :] * phis[None, :] ) / ( kernelVar * kernelVar )\n",
        "\n",
        "      return firstTerm + secondTerm\n",
        "\n",
        "    return innerProduct( b - a, omegas, phis, kernel.variance, lambda_ )\n",
        "\n",
        "@cov.Kuf.register(RVFF_1D, gpflow.kernels.Matern12, TensorLike)\n",
        "def Kuf_matern12_RVFF_1D(inducing_variable, kernel, X):\n",
        "    X = tf.squeeze(X, axis=1)\n",
        "    a, omegas, phis = (lambda u: (u.a, u.omegas, u.phis))(inducing_variable)       \n",
        "    return tf.cos( omegas[:, None] * ( X[None, :] - a + phis[:, None]) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ekb08iAZfo",
        "colab_type": "code",
        "outputId": "48c1bab0-69eb-4fe5-9471-9109e16fc1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "\n",
        "kernel = gpflow.kernels.Matern12(variance=1.0, lengthscales=1.0)\n",
        "likelihood = gpflow.likelihoods.Gaussian()\n",
        "\n",
        "inducing_variable = RVFF_1D( a=2, b=6, M=1000 )\n",
        "\n",
        "model = gpflow.models.SVGP(\n",
        "    kernel=kernel, likelihood=likelihood, inducing_variable=inducing_variable\n",
        ")\n",
        "\n",
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def loss_closure():\n",
        "  return -model.elbo( ( X, Y ) )\n",
        "\n",
        "optimizer.minimize( loss=loss_closure, var_list=model.trainable_variables )"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}