{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VFF_and_RFF_1D.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNPNJO+TevSIek0RJlVJK0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreasICL/MSc_Project/blob/master/code/VFF_and_RFF_1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW-B5syh75r4",
        "colab_type": "code",
        "outputId": "be70325b-003c-487a-be38-39bacde0dab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!pip install gpflow\n",
        "!pip install gast\n",
        "!pip install observations"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpflow in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.8.7)\n",
            "Requirement already satisfied: tensorflow-probability>=0.9 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.10.0rc0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from gpflow) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from gpflow) (1.4.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.7)\n",
            "Requirement already satisfied: multipledispatch>=0.6 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from gpflow) (3.6.6)\n",
            "Requirement already satisfied: gast<0.3,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from gpflow) (2.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9->gpflow) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9->gpflow) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9->gpflow) (1.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (3.2.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.34.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.9.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (46.1.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.6.0.post3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2020.4.5.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.1.0)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: observations in /usr/local/lib/python3.6/dist-packages (0.1.4)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from observations) (1.18.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from observations) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3cwbeHz8Exr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Tuple, Optional\n",
        "import tempfile\n",
        "import pathlib\n",
        "\n",
        "import datetime\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gpflow\n",
        "\n",
        "from gpflow.config import default_float\n",
        "from gpflow.ci_utils import ci_niter\n",
        "from gpflow.utilities import to_default_float\n",
        "from gpflow.base import TensorLike\n",
        "from gpflow import covariances as cov\n",
        "from gpflow import kullback_leiblers as kl\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "from shutil import copyfile, rmtree\n",
        "\n",
        "import observations\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5FxoiegAZe1",
        "colab_type": "text"
      },
      "source": [
        "Make `tensorboard` work inside notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmCOr2hs8355",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_logdir = \"/tmp/tensorboard\"\n",
        "\n",
        "!rm -rf \"{output_logdir}\"\n",
        "!mkdir \"{output_logdir}\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def enumerated_logdir(_logdir_id: int = [0]):\n",
        "    logdir = pathlib.Path(output_logdir, str(_logdir_id[0]))\n",
        "    _logdir_id[0] += 1\n",
        "    return str(logdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A27JdlvAZfE",
        "colab_type": "text"
      },
      "source": [
        "Set up random seeds and default float for `gpflow` tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flnWsQF1_h3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpflow.config.set_default_float(np.float64)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJsA3bUEAZfP",
        "colab_type": "text"
      },
      "source": [
        "## Loading the snelson dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZDkEmxQEqqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  This code was copied from https://github.com/edwardlib/observations/blob/master/observations/snelson1d.py\n",
        "  on 01/05/2020\n",
        "'''\n",
        "\n",
        "from observations.util import maybe_download_and_extract\n",
        "\n",
        "\n",
        "def snelson1d(path):\n",
        "  \"\"\"Load Edward Snelson's 1d regression data set [@snelson2006fitc].\n",
        "  It contains 200 examples of a few oscillations of an example function. It has\n",
        "  seen extensive use as a toy dataset for illustrating qualitative behaviour of\n",
        "  Gaussian process approximations.\n",
        "  Args:\n",
        "    path: str.\n",
        "      Path to directory which either stores file or otherwise file will be\n",
        "      downloaded and extracted there. Filenames are `snelson_train_*`.\n",
        "  Returns:\n",
        "    Tuple of two np.darray `inputs` and `outputs` with 200 rows and 1 column.\n",
        "  \"\"\"\n",
        "  path = os.path.expanduser(path)\n",
        "  inputs_path = os.path.join(path, 'snelson_train_inputs')\n",
        "  outputs_path = os.path.join(path, 'snelson_train_outputs')\n",
        "\n",
        "  # Contains all source as well. We just need the data.\n",
        "  url = 'http://www.gatsby.ucl.ac.uk/~snelson/SPGP_dist.zip'\n",
        "\n",
        "  if not (os.path.exists(inputs_path) and os.path.exists(outputs_path)):\n",
        "    maybe_download_and_extract(path, url)\n",
        "\n",
        "    # Copy the required data\n",
        "    copyfile(os.path.join(path, \"SPGP_dist\", \"train_inputs\"), inputs_path)\n",
        "    copyfile(os.path.join(path, \"SPGP_dist\", \"train_outputs\"), outputs_path)\n",
        "\n",
        "    # Clean up everything else\n",
        "    rmtree(os.path.join(path, \"SPGP_dist\"))\n",
        "    os.remove(os.path.join(path, \"SPGP_dist.zip\"))\n",
        "\n",
        "  X = np.loadtxt(os.path.join(inputs_path))[:, None]\n",
        "  Y = np.loadtxt(os.path.join(outputs_path))[:, None]\n",
        "\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cwgLNj8Hw2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8836d527-7d22-4941-8231-8aaf7fe71b02"
      },
      "source": [
        "X, Y = snelson1d(\".\")\n",
        "num_train_data = X.shape[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Downloading ./SPGP_dist.zip.part \n",
            ">> [14.7 KB/14.7 KB] 6944% @658.1 KB/s,[0s remaining, 1s elapsed]        \n",
            "URL http://www.gatsby.ucl.ac.uk/~snelson/SPGP_dist.zip downloaded to ./SPGP_dist.zip \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg8Cz-6OAZfb",
        "colab_type": "text"
      },
      "source": [
        "Working with TensorFlow Datasets is an efficient way to rapidly shuffle, iterate, and batch from data. For `prefetch` size we use `tf.data.experimental.AUTOTUNE` as recommended by TensorFlow [guidelines](https://www.tensorflow.org/guide/data_performance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUfgEr7aAZfc",
        "colab_type": "code",
        "outputId": "b26cde09-d999-4aec-c87c-4e4f7e10a864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((Xtest, Ytest))\n",
        "\n",
        "batch_size = 32\n",
        "num_features = 10\n",
        "prefetch_size = tf.data.experimental.AUTOTUNE\n",
        "shuffle_buffer_size = num_train_data // 2\n",
        "num_batches_per_epoch = num_train_data // batch_size\n",
        "\n",
        "original_train_dataset = train_dataset\n",
        "train_dataset = (\n",
        "    train_dataset.repeat()\n",
        "    .prefetch(prefetch_size)\n",
        "    .shuffle(buffer_size=shuffle_buffer_size)\n",
        "    .batch(batch_size)\n",
        ")\n",
        "\n",
        "print(f\"prefetch_size={prefetch_size}\")\n",
        "print(f\"shuffle_buffer_size={shuffle_buffer_size}\")\n",
        "print(f\"num_batches_per_epoch={num_batches_per_epoch}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prefetch_size=-1\n",
            "shuffle_buffer_size=100\n",
            "num_batches_per_epoch=6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJdIiObeAZfm",
        "colab_type": "text"
      },
      "source": [
        "## Define a GP model\n",
        "\n",
        "In GPflow 2.0, we use `tf.Module` (or the very thin `gpflow.base.Module` wrapper) to build all our models, as well as their components (kernels, likelihoods, parameters, and so on)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCqAtzWBUhax",
        "colab_type": "text"
      },
      "source": [
        "### 1D Random Variational Fourier Feature Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqaFm4vuUgwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RVFF_1D(gpflow.inducing_variables.InducingVariables):\n",
        "    def __init__(self, a, b, M):\n",
        "        omegasVar = 5\n",
        "        # [a, b] defining the interval of the Fourier representation:\n",
        "        self.a = gpflow.Parameter(a, dtype=gpflow.default_float())\n",
        "        self.b = gpflow.Parameter(b, dtype=gpflow.default_float())\n",
        "        # integer array defining the frequencies, ω_m = 2π (b - a)/m:\n",
        "        self.phis = np.random.uniform(0, 2 * np.pi, size=M) # TODO: fix this\n",
        "        self.omegas = np.random.multivariate_normal( mean = np.zeros( shape=M ), cov = omegasVar * np.identity( M ) )\n",
        "        print(self.omegas)\n",
        "        print(self.phis)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" number of inducing variables (defines dimensionality of q(u)) \"\"\" \n",
        "        return len(self.omegas)  # M sine components"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi5s0D0rlFoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@cov.Kuu.register(RVFF_1D, gpflow.kernels.Matern12)\n",
        "def Kuu_matern12_RVFF_1D(inducing_variable, kernel, jitter=None):\n",
        "    a, b, omegas, phis = (lambda u: (u.a, u.b, u.omegas, u.phis))(inducing_variable)\n",
        "    \n",
        "    lambda_ = 1.0 / kernel.lengthscales\n",
        "\n",
        "    def innerProduct( intervalLen, omegas, phis, kernelVar, lambda_):\n",
        "      angle1 = intervalLen * ( omegas[:, None] - omegas[None, :] ) + omegas[:, None] * phis[:, None] - omegas[None, :] * phis[None, :]\n",
        "      angle2 = intervalLen * ( omegas[:, None] + omegas[None, :] ) + omegas[:, None] * phis[:, None] + omegas[None, :] * phis[None, :]\n",
        "      angle3 = omegas[:, None] * phis[:, None] - omegas[None, :] * phis[None, :]\n",
        "      angle4 = omegas[:, None] * phis[:, None] + omegas[None, :] * phis[None, :]\n",
        "      angle5 = 2 * omegas * ( intervalLen + phis )\n",
        "      angle6 = 2 * omegas * phis\n",
        "\n",
        "      coeff1 = ( omegas[:, None] * omegas[None, :] + lambda_ * lambda_ ) / ( omegas[:, None] - omegas[None, :] )\n",
        "      coeff2 = ( omegas[:, None] * omegas[None, :] - lambda_ * lambda_ ) / ( omegas[:, None] + omegas[None, :] )\n",
        "      coeff3 = ( omegas * omegas - lambda_ * lambda_ ) / ( 2 * omegas )\n",
        "\n",
        "      denom = 4 * kernelVar * kernelVar * lambda_\n",
        "\n",
        "      firstTerm = ( coeff1 * tf.sin( angle1 ) +\n",
        "                    coeff2 * tf.sin( angle2 ) -\n",
        "                    lambda_ * tf.cos( angle2 ) +\n",
        "                    lambda_ * tf.cos( angle1 ) +\n",
        "                    coeff1 * tf.sin( angle3 ) +\n",
        "                    coeff2 * tf.sin( angle4 ) -\n",
        "                    lambda_ * tf.cos( angle4 ) +\n",
        "                    lambda_ * tf.cos( angle3 ) ) / denom\n",
        "\n",
        "      mainDiag = ( ( omegas * omegas + lambda_ * lambda_ ) * intervalLen + \n",
        "                   coeff3 * tf.sin( angle5 ) -\n",
        "                   ( lambda_ * tf.cos( angle5 ) ) - \n",
        "                   ( coeff3 * tf.sin( angle6 ) ) +\n",
        "                   lambda_ * tf.cos( angle6 ) ) / denom\n",
        "\n",
        "      firstTerm = tf.linalg.set_diag( firstTerm, mainDiag )\n",
        "      secondTerm = tf.sin( omegas[:, None] * phis[:, None] ) * tf.sin( omegas[None, :] * phis[None, :] ) / ( kernelVar * kernelVar )\n",
        "      \n",
        "      res = firstTerm + secondTerm\n",
        "      res = 0.5 * (res + tf.transpose(res))\n",
        "\n",
        "      print(\"eigh:\")\n",
        "      print( tf.linalg.eigh(res)[0] )\n",
        "\n",
        "      print(\"==============\")\n",
        "      print(res)\n",
        "\n",
        "      return res\n",
        "\n",
        "    return innerProduct( b - a, omegas, phis, kernel.variance, lambda_ )\n",
        "\n",
        "@cov.Kuf.register(RVFF_1D, gpflow.kernels.Matern12, TensorLike)\n",
        "def Kuf_matern12_RVFF_1D(inducing_variable, kernel, X):\n",
        "    X = tf.squeeze(X, axis=1)\n",
        "    a, omegas, phis = (lambda u: (u.a, u.omegas, u.phis))(inducing_variable)       \n",
        "    return tf.cos( omegas[:, None] * ( X[None, :] - a + phis[:, None]) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ekb08iAZfo",
        "colab_type": "code",
        "outputId": "69d4ad0a-2cb1-46fe-db21-ea5ed58782af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "#w1=-1.16720679; f1=2.98370689; w2=-1.16720679; f2=2.98370689; 0.5*integral_0^4 (sin(w1(s+f1))+w1*cos(w1(s+f1))) * (sin(w2(s+f2))+w2*cos(w2(s+f2))) ds\n",
        "kernel = gpflow.kernels.Matern12(variance=1.0, lengthscales=1.0)\n",
        "likelihood = gpflow.likelihoods.Gaussian()\n",
        "\n",
        "inducing_variable = RVFF_1D( a=2, b=6, M=3 )\n",
        "\n",
        "model = gpflow.models.SVGP(\n",
        "    kernel=kernel, likelihood=likelihood, inducing_variable=inducing_variable\n",
        ")\n",
        "\n",
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def loss_closure():\n",
        "  return -model.elbo( ( X, Y ) )\n",
        "\n",
        "# print( model.elbo((X, Y)) )\n",
        "\n",
        "optimizer.minimize( loss=loss_closure, var_list=model.trainable_variables )\n",
        "print(\"got here\")\n",
        "# print( model.elbo((X, Y)) )\n",
        "# print( tf.linalg.eigh(Kuu_matern12_RVFF_1D(inducing_variable, kernel))[0] )"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.16720679 -2.30816435  2.49133925]\n",
            "[2.98370689 5.68031883 0.22129256]\n",
            "eigh:\n",
            "tf.Tensor([-0.26279206  2.85482678 14.42113773], shape=(3,), dtype=float64)\n",
            "==============\n",
            "tf.Tensor(\n",
            "[[ 2.82913658  0.02800031  0.44911184]\n",
            " [ 0.02800031  6.465702   -7.29387909]\n",
            " [ 0.44911184 -7.29387909  7.71833387]], shape=(3, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-80c6ed6a3861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# print( model.elbo((X, Y)) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# print( model.elbo((X, Y)) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \"\"\"\n\u001b[1;32m    333\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 334\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    386\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m       \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-80c6ed6a3861>\u001b[0m in \u001b[0;36mloss_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# print( model.elbo((X, Y)) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpflow/models/svgp.py\u001b[0m in \u001b[0;36melbo\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_kl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mf_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mvar_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariational_expectations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpflow/models/svgp.py\u001b[0m in \u001b[0;36mpredict_f\u001b[0;34m(self, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mfull_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mwhite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mfull_output_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output_cov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         )\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# tf.debugging.assert_positive(var)  # We really should make the tests pass with this here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/multipledispatch/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMDNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpflow/conditionals/conditionals.py\u001b[0m in \u001b[0;36m_conditional\u001b[0;34m(Xnew, inducing_variable, kernel, f, full_cov, full_output_cov, q_sqrt, white)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mKnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     fmean, fvar = base_conditional(\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mKmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sqrt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     )  # [N, R],  [R, N, N] or [N, R]\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_independent_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpflow/conditionals/util.py\u001b[0m in \u001b[0;36mbase_conditional\u001b[0;34m(Kmn, Kmm, Knn, f, full_cov, q_sqrt, white)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mleading_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKmn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mLm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKmm\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [M, M]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Compute the projection matrix A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cholesky decomposition was not successful. The input might not be valid. [Op:Cholesky]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUMvPD9gLdu4",
        "colab_type": "text"
      },
      "source": [
        "##Testing\n",
        "#Testing whether $q(u) = p(u)$ when the expected log-likelihood = 0. (And hence $ELBO = KL[ q(u) || p(u) ]$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se5vp063L3PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testPriorEqualsPosterior():\n",
        "\n",
        "  class mySVGP(gpflow.models.SVGP):\n",
        "\n",
        "    def __init__(self, kernel, likelihood, inducingVar):\n",
        "      super(mySVGP, self).__init__(\n",
        "          kernel=kernel, likelihood=likelihood, inducing_variable=inducingVar\n",
        "          )\n",
        "\n",
        "    def elbo(self):\n",
        "      return -self.prior_kl()\n",
        "\n",
        "  model = mySVGP(\n",
        "      kernel=kernel, likelihood=likelihood, inducingVar=inducing_variable\n",
        "  )\n",
        "\n",
        "  optimizer = tf.optimizers.Adam()\n",
        "  \n",
        "  @tf.function\n",
        "  def loss_closure():\n",
        "    return -model.elbo()\n",
        "\n",
        "  optimizer.minimize( loss=loss_closure, var_list=model.trainable_variables )\n",
        "\n",
        "testPriorEqualsPosterior()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}