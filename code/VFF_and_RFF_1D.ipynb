{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VFF_and_RFF_1D.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYbjc2hV2NpQD1XlDDpMj/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreasICL/MSc_Project/blob/master/code/VFF_and_RFF_1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW-B5syh75r4",
        "colab_type": "code",
        "outputId": "b8c4e011-7963-4ab2-906a-39fc928fae6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!pip install gpflow\n",
        "!pip install gast\n",
        "!pip install observations"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpflow in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from gpflow) (2.2.0rc4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from gpflow) (3.6.6)\n",
            "Requirement already satisfied: tensorflow-probability>=0.9 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.10.0rc0)\n",
            "Requirement already satisfied: multipledispatch>=0.6 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.6.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.8.7)\n",
            "Requirement already satisfied: gast<0.3,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from gpflow) (0.2.2)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from gpflow) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from gpflow) (1.18.4)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.28.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->gpflow) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9->gpflow) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9->gpflow) (4.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (46.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.24.3)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->gpflow) (3.1.0)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: observations in /usr/local/lib/python3.6/dist-packages (0.1.4)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from observations) (1.18.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from observations) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3cwbeHz8Exr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Tuple, Optional\n",
        "import tempfile\n",
        "import pathlib\n",
        "\n",
        "import datetime\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gpflow\n",
        "\n",
        "from gpflow.config import default_float\n",
        "from gpflow.ci_utils import ci_niter\n",
        "from gpflow.utilities import to_default_float\n",
        "from gpflow.base import TensorLike\n",
        "from gpflow import covariances as cov\n",
        "from gpflow import kullback_leiblers as kl\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "from shutil import copyfile, rmtree\n",
        "\n",
        "import observations\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5FxoiegAZe1",
        "colab_type": "text"
      },
      "source": [
        "Make `tensorboard` work inside notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmCOr2hs8355",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_logdir = \"/tmp/tensorboard\"\n",
        "\n",
        "!rm -rf \"{output_logdir}\"\n",
        "!mkdir \"{output_logdir}\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def enumerated_logdir(_logdir_id: int = [0]):\n",
        "    logdir = pathlib.Path(output_logdir, str(_logdir_id[0]))\n",
        "    _logdir_id[0] += 1\n",
        "    return str(logdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A27JdlvAZfE",
        "colab_type": "text"
      },
      "source": [
        "Set up random seeds and default float for `gpflow` tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flnWsQF1_h3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpflow.config.set_default_float(np.float64)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJsA3bUEAZfP",
        "colab_type": "text"
      },
      "source": [
        "## Loading the snelson dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZDkEmxQEqqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  This code was copied from https://github.com/edwardlib/observations/blob/master/observations/snelson1d.py\n",
        "  on 01/05/2020\n",
        "'''\n",
        "\n",
        "from observations.util import maybe_download_and_extract\n",
        "\n",
        "\n",
        "def snelson1d(path):\n",
        "  \"\"\"Load Edward Snelson's 1d regression data set [@snelson2006fitc].\n",
        "  It contains 200 examples of a few oscillations of an example function. It has\n",
        "  seen extensive use as a toy dataset for illustrating qualitative behaviour of\n",
        "  Gaussian process approximations.\n",
        "  Args:\n",
        "    path: str.\n",
        "      Path to directory which either stores file or otherwise file will be\n",
        "      downloaded and extracted there. Filenames are `snelson_train_*`.\n",
        "  Returns:\n",
        "    Tuple of two np.darray `inputs` and `outputs` with 200 rows and 1 column.\n",
        "  \"\"\"\n",
        "  path = os.path.expanduser(path)\n",
        "  inputs_path = os.path.join(path, 'snelson_train_inputs')\n",
        "  outputs_path = os.path.join(path, 'snelson_train_outputs')\n",
        "\n",
        "  # Contains all source as well. We just need the data.\n",
        "  url = 'http://www.gatsby.ucl.ac.uk/~snelson/SPGP_dist.zip'\n",
        "\n",
        "  if not (os.path.exists(inputs_path) and os.path.exists(outputs_path)):\n",
        "    maybe_download_and_extract(path, url)\n",
        "\n",
        "    # Copy the required data\n",
        "    copyfile(os.path.join(path, \"SPGP_dist\", \"train_inputs\"), inputs_path)\n",
        "    copyfile(os.path.join(path, \"SPGP_dist\", \"train_outputs\"), outputs_path)\n",
        "\n",
        "    # Clean up everything else\n",
        "    rmtree(os.path.join(path, \"SPGP_dist\"))\n",
        "    os.remove(os.path.join(path, \"SPGP_dist.zip\"))\n",
        "\n",
        "  X = np.loadtxt(os.path.join(inputs_path))[:, None]\n",
        "  Y = np.loadtxt(os.path.join(outputs_path))[:, None]\n",
        "\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cwgLNj8Hw2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y = snelson1d(\".\")\n",
        "num_train_data = X.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg8Cz-6OAZfb",
        "colab_type": "text"
      },
      "source": [
        "Working with TensorFlow Datasets is an efficient way to rapidly shuffle, iterate, and batch from data. For `prefetch` size we use `tf.data.experimental.AUTOTUNE` as recommended by TensorFlow [guidelines](https://www.tensorflow.org/guide/data_performance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUfgEr7aAZfc",
        "colab_type": "code",
        "outputId": "758972b9-935e-41e8-a7d0-bbb7582da66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((Xtest, Ytest))\n",
        "\n",
        "batch_size = 32\n",
        "num_features = 10\n",
        "prefetch_size = tf.data.experimental.AUTOTUNE\n",
        "shuffle_buffer_size = num_train_data // 2\n",
        "num_batches_per_epoch = num_train_data // batch_size\n",
        "\n",
        "original_train_dataset = train_dataset\n",
        "train_dataset = (\n",
        "    train_dataset.repeat()\n",
        "    .prefetch(prefetch_size)\n",
        "    .shuffle(buffer_size=shuffle_buffer_size)\n",
        "    .batch(batch_size)\n",
        ")\n",
        "\n",
        "print(f\"prefetch_size={prefetch_size}\")\n",
        "print(f\"shuffle_buffer_size={shuffle_buffer_size}\")\n",
        "print(f\"num_batches_per_epoch={num_batches_per_epoch}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prefetch_size=-1\n",
            "shuffle_buffer_size=100\n",
            "num_batches_per_epoch=6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJdIiObeAZfm",
        "colab_type": "text"
      },
      "source": [
        "## Define a GP model\n",
        "\n",
        "In GPflow 2.0, we use `tf.Module` (or the very thin `gpflow.base.Module` wrapper) to build all our models, as well as their components (kernels, likelihoods, parameters, and so on)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCqAtzWBUhax",
        "colab_type": "text"
      },
      "source": [
        "### 1D Random Variational Fourier Feature Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqaFm4vuUgwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RVFF_1D(gpflow.inducing_variables.InducingVariables):\n",
        "    def __init__(self, a, b, M):\n",
        "        # [a, b] defining the interval of the Fourier representation:\n",
        "        self.a = gpflow.Parameter(a, dtype=gpflow.default_float())\n",
        "        self.b = gpflow.Parameter(b, dtype=gpflow.default_float())\n",
        "        # integer array defining the frequencies, ω_m = 2π (b - a)/m:\n",
        "        # self.omegas = 2.0 * np.pi * np.arange(M, dtype=default_float()) / (b - a) + 1 # TODO: fix this\n",
        "        self.omegas = 2.0 * np.pi * np.random.uniform(1, 500, size=M) / (b - a) + 1 # TODO: fix this\n",
        "        self.phis = np.random.multivariate_normal( mean=a * np.ones( shape=M ), cov=np.identity( M ) )\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" number of inducing variables (defines dimensionality of q(u)) \"\"\" \n",
        "        return len(self.omegas)  # M sine components"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi5s0D0rlFoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@cov.Kuu.register(RVFF_1D, gpflow.kernels.Matern12)\n",
        "def Kuu_matern12_RVFF_1D(inducing_variable, kernel, jitter=None):\n",
        "    a, b, omegas, phis = (lambda u: (u.a, u.b, u.omegas, u.phis))(inducing_variable)\n",
        "    \n",
        "    lambda_ = 1.0 / kernel.lengthscales\n",
        "\n",
        "    def innerProduct( intervalLen, omegas, phis, kernelVar, lambda_):\n",
        "      angle1 = intervalLen * ( omegas[:, None] - omegas[None, :] ) + omegas[:, None] * phis[:, None] - omegas[None, :] * phis[None, :]\n",
        "      angle2 = intervalLen * ( omegas[:, None] + omegas[None, :] ) + omegas[:, None] * phis[:, None] + omegas[None, :] * phis[None, :]\n",
        "      angle3 = omegas[:, None] * phis[:, None] - omegas[None, :] * phis[None, :]\n",
        "      angle4 = omegas[:, None] * phis[:, None] + omegas[None, :] * phis[None, :]\n",
        "      angle5 = 2 * omegas * ( intervalLen + phis )\n",
        "      angle6 = 2 * omegas * phis\n",
        "\n",
        "      coeff1 = ( omegas[:, None] * omegas[None, :] + lambda_ * lambda_ ) / ( omegas[:, None] - omegas[None, :] )\n",
        "      coeff2 = ( omegas[:, None] * omegas[None, :] - lambda_ * lambda_ ) / ( omegas[:, None] + omegas[None, :] )\n",
        "      coeff3 = ( omegas * omegas - lambda_ * lambda_ ) / ( 2 * omegas )\n",
        "\n",
        "      denom = 4 * kernelVar * kernelVar * lambda_\n",
        "\n",
        "      firstTerm = ( coeff1 * tf.sin( angle1 ) +\n",
        "                    coeff2 * tf.sin( angle2 ) -\n",
        "                    lambda_ * tf.cos( angle2 ) +\n",
        "                    lambda_ * tf.cos( angle1 ) +\n",
        "                    coeff1 * tf.sin( angle3 ) +\n",
        "                    coeff2 * tf.sin( angle4 ) -\n",
        "                    lambda_ * tf.cos( angle4 ) +\n",
        "                    lambda_ * tf.cos( angle3 ) ) / denom\n",
        "\n",
        "      mainDiag = ( ( omegas * omegas + lambda_ * lambda_ ) * intervalLen + \n",
        "                   coeff3 * tf.sin( angle5 ) -\n",
        "                   ( lambda_ * tf.cos( angle5 ) ) - \n",
        "                   ( coeff3 * tf.sin( angle6 ) ) +\n",
        "                   lambda_ * tf.cos( angle6 ) ) / denom\n",
        "\n",
        "      firstTerm = tf.linalg.set_diag( firstTerm, mainDiag )\n",
        "      secondTerm = tf.sin( omegas[:, None] * phis[:, None] ) * tf.sin( omegas[None, :] * phis[None, :] ) / ( kernelVar * kernelVar )\n",
        "      \n",
        "      res = firstTerm + secondTerm\n",
        "      res = 0.5 * (res + tf.transpose(res))\n",
        "\n",
        "      print( tf.linalg.eigh(res)[0] )\n",
        "\n",
        "      return res\n",
        "\n",
        "    return innerProduct( b - a, omegas, phis, kernel.variance, lambda_ )\n",
        "\n",
        "@cov.Kuf.register(RVFF_1D, gpflow.kernels.Matern12, TensorLike)\n",
        "def Kuf_matern12_RVFF_1D(inducing_variable, kernel, X):\n",
        "    X = tf.squeeze(X, axis=1)\n",
        "    a, omegas, phis = (lambda u: (u.a, u.omegas, u.phis))(inducing_variable)       \n",
        "    return tf.cos( omegas[:, None] * ( X[None, :] - a + phis[:, None]) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1ekb08iAZfo",
        "colab_type": "code",
        "outputId": "95f3db8d-f28b-421a-d2fc-7e1c28f9db51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "\n",
        "kernel = gpflow.kernels.Matern12(variance=1.0, lengthscales=1.0)\n",
        "likelihood = gpflow.likelihoods.Gaussian()\n",
        "\n",
        "inducing_variable = RVFF_1D( a=2, b=6, M=10 )\n",
        "\n",
        "model = gpflow.models.SVGP(\n",
        "    kernel=kernel, likelihood=likelihood, inducing_variable=inducing_variable\n",
        ")\n",
        "\n",
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def loss_closure():\n",
        "  return -model.elbo( ( X, Y ) )\n",
        "\n",
        "print( model.elbo((X, Y)) )\n",
        "\n",
        "optimizer.minimize( loss=loss_closure, var_list=model.trainable_variables )\n",
        "\n",
        "print( model.elbo((X, Y)) )\n",
        "# print( tf.linalg.eigh(Kuu_matern12_RVFF_1D(inducing_variable, kernel))[0] )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(-366.53757186314385, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-18f8717710c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# print( tf.linalg.eigh(Kuu_matern12_RVFF_1D(inducing_variable, kernel))[0] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpflow/models/svgp.py\u001b[0m in \u001b[0;36melbo\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_kl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mf_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mvar_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariational_expectations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpflow/models/svgp.py\u001b[0m in \u001b[0;36mpredict_f\u001b[0;34m(self, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mfull_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mwhite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mfull_output_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output_cov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         )\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# tf.debugging.assert_positive(var)  # We really should make the tests pass with this here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/multipledispatch/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMDNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpflow/conditionals/conditionals.py\u001b[0m in \u001b[0;36m_conditional\u001b[0;34m(Xnew, inducing_variable, kernel, f, full_cov, full_output_cov, q_sqrt, white)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mKnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     fmean, fvar = base_conditional(\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mKmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_sqrt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     )  # [N, R],  [R, N, N] or [N, R]\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_independent_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpflow/conditionals/util.py\u001b[0m in \u001b[0;36mbase_conditional\u001b[0;34m(Kmn, Kmm, Knn, f, full_cov, q_sqrt, white)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Compute the projection matrix A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mLm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleading_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [..., M, M]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriangular_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [..., M, N]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# compute the covariance due to the conditioning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg_ops.py\u001b[0m in \u001b[0;36mmatrix_triangular_solve\u001b[0;34m(matrix, rhs, lower, adjoint, name)\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'triangular_solve'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     return gen_linalg_ops.matrix_triangular_solve(\n\u001b[0;32m--> 141\u001b[0;31m         matrix, rhs, lower=lower, adjoint=adjoint)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36mmatrix_triangular_solve\u001b[0;34m(matrix, rhs, lower, adjoint, name)\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1888\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1889\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input matrix is not invertible. [Op:MatrixTriangularSolve]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUMvPD9gLdu4",
        "colab_type": "text"
      },
      "source": [
        "##Testing\n",
        "#Testing whether $q(u) = p(u)$ when the expected log-likelihood = 0. (And hence $ELBO = KL[ q(u) || p(u) ]$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se5vp063L3PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testPriorEqualsPosterior():\n",
        "\n",
        "  class mySVGP(gpflow.models.SVGP):\n",
        "\n",
        "    def __init__(self, kernel, likelihood, inducingVar):\n",
        "      super(mySVGP, self).__init__(\n",
        "          kernel=kernel, likelihood=likelihood, inducing_variable=inducingVar\n",
        "          )\n",
        "\n",
        "    def elbo(self):\n",
        "      return -self.prior_kl()\n",
        "\n",
        "  model = mySVGP(\n",
        "      kernel=kernel, likelihood=likelihood, inducingVar=inducing_variable\n",
        "  )\n",
        "\n",
        "  optimizer = tf.optimizers.Adam()\n",
        "  \n",
        "  @tf.function\n",
        "  def loss_closure():\n",
        "    return -model.elbo()\n",
        "\n",
        "  optimizer.minimize( loss=loss_closure, var_list=model.trainable_variables )\n",
        "\n",
        "testPriorEqualsPosterior()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}